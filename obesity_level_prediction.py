# -*- coding: utf-8 -*-
"""obesity_level_prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zHwjrZXlnWiw4w_wPILIBjUdBsCfKrpf
"""

from ucimlrepo import fetch_ucirepo

# fetch dataset
estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544)

# data (as pandas dataframes)
X = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features
y = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets

# metadata
print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.metadata)

# variable information
print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.variables)

import pandas as pd

# Combine features and target into one DataFrame
df = pd.concat([X, y], axis=1)

# Check for any rows with missing/null values
print("Rows with missing values (if any):")
print(df[df.isnull().any(axis=1)].head())

#  Drop missing values
df.dropna(inplace=True)
print("\nMissing values dropped.")

# Check for duplicate rows
has_duplicates = df.duplicated().any()
print(f"\nAny duplicate rows? {has_duplicates}")

# Drop duplicates rows
if has_duplicates:
    before = df.shape[0]
    df.drop_duplicates(inplace=True)
    after = df.shape[0]
    print(f"{before - after} duplicate rows removed.")

# Final shape of the cleaned DataFrame
print("\nFinal DataFrame shape:", df.shape)

# Check object type columns
df.dtypes=='object'

# Factorize selected categorical columns
df['Gender'], c =pd.factorize(df['Gender'])
df['family_history_with_overweight'], c = pd.factorize(df['family_history_with_overweight'])
# Correcting column names based on the dataframe
df['FAVC'], c = pd.factorize(df['FAVC']) # Correcting FCOHCF to FAVC
df['SMOKE'], c = pd.factorize(df['SMOKE']) # Correcting Smoke to SMOKE
df['SCC'], c = pd.factorize(df['SCC']) # Correcting Calorie_Consump_Monitoring to SCC

# Function to convert to dummies
def dummies(x,df):
    temp = pd.get_dummies(df[x], drop_first = True)
    df = pd.concat([df, temp], axis = 1)
    df.drop([x], axis = 1, inplace = True)
    return df

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

# Label encode other categorical columns
df['NObeyesdad'] = le.fit_transform(df['NObeyesdad'])
df['CAEC'] = le.fit_transform(df['CAEC'])
df['CALC'] = le.fit_transform(df['CALC'])
df['MTRANS'] = le.fit_transform(df['MTRANS'])

# Display the NObeyesdad column
print(df['NObeyesdad'])

# Now devide dataframe into X and y
# X = Independant features
# y = Target feature

X = df.iloc[:,:-1]
y = df['NObeyesdad'] # Use 'NObeyesdad' as this is the actual column name after cleaning and encoding

from sklearn.model_selection import train_test_split

# Split dataset into training and test set
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=40)

print("Training features shape:", train_X.shape)
print("Testing features shape:", test_X.shape)
print("Training target shape:", train_y.shape)
print("Testing target shape:", test_y.shape)

import warnings
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

# Suppress only the specific convergence warning
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# Creating logistic regression model
logistic_model = LogisticRegression(max_iter=1000)

# Fitting the model
logistic_model.fit(train_X, train_y)

# Determining score of test and train dataset
print('Training score is: %0.2f' % logistic_model.score(train_X, train_y))
print('Testing score is: %0.2f' % logistic_model.score(test_X, test_y))

# Predicting the model
pred_logistic = logistic_model.predict(test_X)

# Accuracy using accuracy_score
logistic_model_accuracy = accuracy_score(test_y, pred_logistic)
print('Logistic Regression Model Accuracy: %0.2f' % logistic_model_accuracy)

# Classification report
logistic_model_CR = classification_report(test_y, pred_logistic)
print("\nClassification Report:")
print(logistic_model_CR)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Define class names corresponding to the encoded labels (0-6)
# Based on the value_counts() output for NObeyesdad and the variable information
# 0: Insufficient Weight
# 1: Normal Weight
# 2: Overweight Level I
# 3: Overweight Level II
# 4: Obesity Type I
# 5: Obesity Type II
# 6: Obesity Type III
class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']


# Generate the confusion matrix for the logistic regression model
cm_logistic = confusion_matrix(test_y, pred_logistic)

# Plot the confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm_logistic, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=class_names, yticklabels=class_names) # Use class_names for labels
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Logistic Regression Model')
plt.show()

# Creating DT model
from sklearn.tree import DecisionTreeClassifier

# Creating Decision Tree Classifier with max_depth=4
dt_model = DecisionTreeClassifier(max_depth=4)

# Training the model
dt_model.fit(train_X, train_y)

# Determining score of test and train dataset
print('Training score is: %0.2f' % dt_model.score(train_X, train_y))
print('Testing score is: %0.2f' % dt_model.score(test_X, test_y))

# Predicting the model
pred_dt = dt_model.predict(test_X)

# Accuracy using accuracy_score
dt_model_accuracy = accuracy_score(test_y, pred_dt)
print('Decision Tree Model Accuracy: %0.2f' % dt_model_accuracy)

# Classification report
dt_model_CR = classification_report(test_y, pred_dt)
print("\nClassification Report:")
print(dt_model_CR)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Class names based on label encoding (reusing the list defined earlier)
# class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I',
#                'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']


# Generate the confusion matrix for the Decision Tree model
cm_dt = confusion_matrix(test_y, pred_dt)

# Plot the confusion matrix for Decision Tree as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Decision Tree Model')
plt.tight_layout()
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Creating RF model
rf_model = RandomForestClassifier()

# Training the model
rf_model.fit(train_X, train_y)

# Predicting the model
pred_rf = rf_model.predict(test_X)

# Determining score of test and train dataset
print('Training score is: %0.2f' %rf_model.score(train_X, train_y))
print('Testing score is: %0.2f' %rf_model.score(test_X, test_y))
print('The accuracy of the model is :%0.2f' %accuracy_score(test_y, pred_rf))

# Classification report
rf_model_CR = classification_report(test_y, pred_rf)
print("\nClassification Report:")
print(rf_model_CR)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Class names based on label encoding
class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I',
               'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']

# Generate the confusion matrix for the Random Forest model
cm_rf = confusion_matrix(test_y, pred_rf)

# Plot the confusion matrix for Random Forest as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Random Forest Model')
plt.tight_layout()
plt.show()

import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from xgboost import plot_importance
from sklearn.metrics import accuracy_score, classification_report

# Creating XGBoost model
xgb_model = XGBClassifier(eval_metric='mlogloss')

# Training the model
xgb_model.fit(train_X, train_y)

# Predicting the model
pred_xgb = xgb_model.predict(test_X)

# Determining score of test and train dataset
print('Training score is: %0.2f' %xgb_model.score(train_X, train_y))
print('Testing score is: %0.2f' %xgb_model.score(test_X, test_y))
print('The accuracy of the model is :%0.2f' %accuracy_score(test_y, pred_xgb))

# Classification report
xgb_model_CR = classification_report(test_y, pred_xgb)
print("\nClassification Report:")
print(xgb_model_CR)

# Generate the confusion matrix for the XGBoost model
cm_xgb = confusion_matrix(test_y, pred_xgb)

# Plot the confusion matrix for XGBoost as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for XGBoost Model')
plt.tight_layout()
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score
import pandas as pd

# Calculate precision, recall, and f1-score for each model
precision_logistic = precision_score(test_y, pred_logistic, average='weighted')
recall_logistic = recall_score(test_y, pred_logistic, average='weighted')
f1_logistic = f1_score(test_y, pred_logistic, average='weighted')

precision_dt = precision_score(test_y, pred_dt, average='weighted')
recall_dt = recall_score(test_y, pred_dt, average='weighted')
f1_dt = f1_score(test_y, pred_dt, average='weighted')

precision_rf = precision_score(test_y, pred_rf, average='weighted')
recall_rf = recall_score(test_y, pred_rf, average='weighted')
f1_rf = f1_score(test_y, pred_rf, average='weighted')

precision_xgb = precision_score(test_y, pred_xgb, average='weighted')
recall_xgb = recall_score(test_y, pred_xgb, average='weighted')
f1_xgb = f1_score(test_y, pred_xgb, average='weighted')


# Creating dataframe of performance metrics
result_metrics = pd.DataFrame({
    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],
    'Accuracy': [
        accuracy_score(test_y, pred_logistic),
        accuracy_score(test_y, pred_dt),
        accuracy_score(test_y, pred_rf),
        accuracy_score(test_y, pred_xgb)
    ],
    'Precision': [
        precision_logistic,
        precision_dt,
        precision_rf,
        precision_xgb
    ],
    'Recall': [
        recall_logistic,
        recall_dt,
        recall_rf,
        recall_xgb
    ],
    'F1-Score': [
        f1_logistic,
        f1_dt,
        f1_rf,
        f1_xgb
    ]
})

# Format metrics to two decimal places
result_metrics['Accuracy'] = result_metrics['Accuracy'].map('{:.2f}'.format)
result_metrics['Precision'] = result_metrics['Precision'].map('{:.2f}'.format)
result_metrics['Recall'] = result_metrics['Recall'].map('{:.2f}'.format)
result_metrics['F1-Score'] = result_metrics['F1-Score'].map('{:.2f}'.format)


display(result_metrics)

# Only run this cell *after* you've already created metrics_dfimport matplotlib.pyplot as plt

metrics = ["Accuracy", "Precision", "Recall", "F1-Score"]

# Convert the metrics columns to numeric types for plotting
result_metrics[metrics] = result_metrics[metrics].astype(float)

for metric in metrics:
    plt.figure(figsize=(8, 5))
    # Use the correct DataFrame name and plot the metric for each model
    plt.bar(result_metrics['Model'], result_metrics[metric], color='skyblue', edgecolor='black')
    plt.title(f"{metric} Comparison Across Models")
    plt.ylabel(metric)
    plt.xlabel("Model")
    plt.xticks(rotation=45)
    plt.ylim(0, 1.0)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()