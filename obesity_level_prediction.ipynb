{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# 1. Dataset Loading\n",
        "# =======================================================\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Fetch dataset from the UCI Machine Learning Repository\n",
        "dataset = fetch_ucirepo(id=544)\n",
        "\n",
        "# Separate features and target variables\n",
        "X = dataset.data.features\n",
        "y = dataset.data.targets\n",
        "\n",
        "# Dataset metadata and variable descriptions available on UCI repository"
      ],
      "metadata": {
        "id": "Y-6VsbEPdm4F",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# 2. Data Cleaning and Preprocessing\n",
        "# ===================================================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Combine features and target into a single DataFrame\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "#  Remove missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate rows if any exist\n",
        "if df.duplicated().any()\n",
        "    df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "fr8p6mt5ehjZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# 3. Feature Encoding\n",
        "# ===================================================\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode binary categorical features\n",
        "df['Gender'], c =pd.factorize(df['Gender'])\n",
        "df['family_history_with_overweight'], c = pd.factorize(df['family_history_with_overweight'])\n",
        "# Correcting column names based on the dataframe\n",
        "df['FAVC'], c = pd.factorize(df['FAVC']) # Correcting FCOHCF to FAVC\n",
        "df['SMOKE'], c = pd.factorize(df['SMOKE']) # Correcting Smoke to SMOKE\n",
        "df['SCC'], c = pd.factorize(df['SCC']) # Correcting Calorie_Consump_Monitoring to SCC\n",
        "\n",
        "# Initialize label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Label encode other categorical columns\n",
        "df['NObeyesdad'] = le.fit_transform(df['NObeyesdad'])\n",
        "df['CAEC'] = le.fit_transform(df['CAEC'])\n",
        "df['CALC'] = le.fit_transform(df['CALC'])\n",
        "df['MTRANS'] = le.fit_transform(df['MTRANS'])\n"
      ],
      "metadata": {
        "id": "G_wD0p8SjPxK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 4. Feature-Target Separation\n",
        "# =====================================================\n",
        "\n",
        "# Separate independent features (X) and target variable (y)\n",
        "X = df.drop(columns=['NObeyesdad'])\n",
        "y = df['NObeyesdad']"
      ],
      "metadata": {
        "id": "qY7R_UGGVExB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9910761c",
        "collapsed": true
      },
      "source": [
        "# ========================================================\n",
        "# 5. Train-Test Split\n",
        "# ========================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training and test set\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=40, stratify=y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4209c301",
        "collapsed": true
      },
      "source": [
        "# =======================================================\n",
        "# 6.1 Logistic Regression Model\n",
        "# =======================================================\n",
        "\n",
        "\n",
        "import warnings\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Suppress only the specific convergence warning\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(train_X, train_y)\n",
        "\n",
        "# Generate predictions\n",
        "pred_logistic = logistic_model.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# 6.1.1 Logistic Regression - Confusion Matrix\n",
        "# =================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define class names corresponding to the encoded labels (0-6)\n",
        "# Based on the value_counts() output for NObeyesdad and the variable information\n",
        "# 0: Insufficient Weight\n",
        "# 1: Normal Weight\n",
        "# 2: Overweight Level I\n",
        "# 3: Overweight Level II\n",
        "# 4: Obesity Type I\n",
        "# 5: Obesity Type II\n",
        "# 6: Obesity Type III\n",
        "class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']\n",
        "\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm_logistic = confusion_matrix(test_y, pred_logistic)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_logistic, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names) # Use class_names for labels\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix for Logistic Regression Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e3EZdJdYpYtH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b3e4bd6",
        "collapsed": true
      },
      "source": [
        "# =======================================================\n",
        "# 6.2 Decision Tree Model\n",
        "# =======================================================\n",
        "\n",
        "# Creating DT model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and train Decision Tree classifier\n",
        "dt_model = DecisionTreeClassifier(max_depth=4, random_state=40)\n",
        "dt_model.fit(train_X, train_y)\n",
        "\n",
        "# Predicting the model\n",
        "pred_dt = dt_model.predict(test_X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# 6.2.1 Decision Tree - Confusion Matrix\n",
        "# =============================================\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Class names based on label encoding (reusing the list defined earlier)\n",
        "# class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I',\n",
        "#                'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']\n",
        "\n",
        "\n",
        "# Generate the confusion matrix for the Decision Tree model\n",
        "cm_dt = confusion_matrix(test_y, pred_dt)\n",
        "\n",
        "# Plot the confusion matrix for Decision Tree as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix for Decision Tree Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vIMLmWjMJDmT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d303196",
        "collapsed": true
      },
      "source": [
        "# =================================================================\n",
        "# 6.3 Random Forest Model\n",
        "# =================================================================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Initialize and train Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=40)\n",
        "rf_model.fit(train_X, train_y)\n",
        "\n",
        "# Generate predictions\n",
        "pred_rf = rf_model.predict(test_X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 6.3.1 Random Forest - Confusion Matrix\n",
        "# ==================================================\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Class names based on label encoding\n",
        "class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight_Level_I',\n",
        "               'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III']\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm_rf = confusion_matrix(test_y, pred_rf)\n",
        "\n",
        "# Plot the confusion matrix for Random Forest as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix for Random Forest Model')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UWm3nKpir0P6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e9fcca9",
        "collapsed": true
      },
      "source": [
        "# =======================================================\n",
        "# 6.4 XGBoost Model\n",
        "# =======================================================\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and train XGBoost classifier\n",
        "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=40, use_label_encoder=False)\n",
        "xgb_model.fit(train_X, train_y)\n",
        "\n",
        "# Generate predictions\n",
        "pred_xgb = xgb_model.predict(test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# 6.4.1 XGBoost - Confusion Matrix\n",
        "# ========================================================\n",
        "\n",
        "# Generate the confusion matrix for the XGBoost model\n",
        "cm_xgb = confusion_matrix(test_y, pred_xgb)\n",
        "\n",
        "# Plot the confusion matrix for XGBoost as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix for XGBoost Model')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cwkeUdVIr3ty",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b58875b",
        "collapsed": true
      },
      "source": [
        "# ======================================================\n",
        "# 7. Model Performance Comparison\n",
        "# ======================================================\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate precision, recall, and f1-score for each model\n",
        "precision_logistic = precision_score(test_y, pred_logistic, average='weighted')\n",
        "recall_logistic = recall_score(test_y, pred_logistic, average='weighted')\n",
        "f1_logistic = f1_score(test_y, pred_logistic, average='weighted')\n",
        "\n",
        "precision_dt = precision_score(test_y, pred_dt, average='weighted')\n",
        "recall_dt = recall_score(test_y, pred_dt, average='weighted')\n",
        "f1_dt = f1_score(test_y, pred_dt, average='weighted')\n",
        "\n",
        "precision_rf = precision_score(test_y, pred_rf, average='weighted')\n",
        "recall_rf = recall_score(test_y, pred_rf, average='weighted')\n",
        "f1_rf = f1_score(test_y, pred_rf, average='weighted')\n",
        "\n",
        "precision_xgb = precision_score(test_y, pred_xgb, average='weighted')\n",
        "recall_xgb = recall_score(test_y, pred_xgb, average='weighted')\n",
        "f1_xgb = f1_score(test_y, pred_xgb, average='weighted')\n",
        "\n",
        "\n",
        "# Creating dataframe of performance metrics\n",
        "result_metrics = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(test_y, pred_logistic),\n",
        "        accuracy_score(test_y, pred_dt),\n",
        "        accuracy_score(test_y, pred_rf),\n",
        "        accuracy_score(test_y, pred_xgb)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_logistic,\n",
        "        precision_dt,\n",
        "        precision_rf,\n",
        "        precision_xgb\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_logistic,\n",
        "        recall_dt,\n",
        "        recall_rf,\n",
        "        recall_xgb\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        f1_logistic,\n",
        "        f1_dt,\n",
        "        f1_rf,\n",
        "        f1_xgb\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Format metrics to two decimal places\n",
        "result_metrics['Accuracy'] = result_metrics['Accuracy'].map('{:.2f}'.format)\n",
        "result_metrics['Precision'] = result_metrics['Precision'].map('{:.2f}'.format)\n",
        "result_metrics['Recall'] = result_metrics['Recall'].map('{:.2f}'.format)\n",
        "result_metrics['F1-Score'] = result_metrics['F1-Score'].map('{:.2f}'.format)\n",
        "\n",
        "# Display comparison table\n",
        "display(result_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# 7.1 Visual Comparison of Model Performance\n",
        "# ===================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
        "\n",
        "# Convert the metrics columns to numeric types for plotting\n",
        "result_metrics[metrics] = result_metrics[metrics].astype(float)\n",
        "\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    # Use the correct DataFrame name and plot the metric for each model\n",
        "    plt.bar(result_metrics['Model'], result_metrics[metric], color='skyblue', edgecolor='black')\n",
        "    plt.title(f\"{metric} Comparison Across Models\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel(\"Model\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PD6YdAsB35oc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}